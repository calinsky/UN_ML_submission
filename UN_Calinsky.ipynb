{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UN ML Assessment\n",
    "### Rebecca Calinsky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. How did you approach the problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used HuggingFace’s transformers library, as it provides pretrained model options for abstractive summarization. One issue that I came across is that the length of the original texts are quite long (over the 1024-word limit), and I resolved this problem by breaking each original text into groups of sub-texts, summarizing them separately, and then re-summarizing their merged result. Due to computation restraints, I generated only the first 150 (2%) of the 7,507 summaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. In this problem, how can you measure the performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to measure performance would be to randomly choose N of the original texts, summarize each of these myself (or ideally, with a few independent unbiased annotators), and then compare these human-made summarizations with the generated summaries. I would then rate each generated summary based on how many of the salient points from the annotated summary are present. The overall performance rating would be an average of these N ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load and preview data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "import pandas as pd\n",
    "Data = pd.read_csv(\"un-general-debates.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>year</th>\n",
       "      <th>country</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>1989</td>\n",
       "      <td>MDV</td>\n",
       "      <td>﻿It is indeed a pleasure for me and the member...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>1989</td>\n",
       "      <td>FIN</td>\n",
       "      <td>﻿\\nMay I begin by congratulating you. Sir, on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>1989</td>\n",
       "      <td>NER</td>\n",
       "      <td>﻿\\nMr. President, it is a particular pleasure ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>1989</td>\n",
       "      <td>URY</td>\n",
       "      <td>﻿\\nDuring the debate at the fortieth session o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44</td>\n",
       "      <td>1989</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>﻿I should like at the outset to express my del...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7502</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>KAZ</td>\n",
       "      <td>﻿This session\\nthat is taking place under extr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7503</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>LBR</td>\n",
       "      <td>﻿I am honoured to\\nparticipate in this histori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7504</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>BDI</td>\n",
       "      <td>﻿It\\nis for me a signal honour to take the flo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7505</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>HUN</td>\n",
       "      <td>﻿First, may I congratulate Mr. Han Seung-soo o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7506</th>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>KWT</td>\n",
       "      <td>﻿On behalf of the State of Kuwait, it\\ngives m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7507 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      session  year country                                               text\n",
       "0          44  1989     MDV  ﻿It is indeed a pleasure for me and the member...\n",
       "1          44  1989     FIN  ﻿\\nMay I begin by congratulating you. Sir, on ...\n",
       "2          44  1989     NER  ﻿\\nMr. President, it is a particular pleasure ...\n",
       "3          44  1989     URY  ﻿\\nDuring the debate at the fortieth session o...\n",
       "4          44  1989     ZWE  ﻿I should like at the outset to express my del...\n",
       "...       ...   ...     ...                                                ...\n",
       "7502       56  2001     KAZ  ﻿This session\\nthat is taking place under extr...\n",
       "7503       56  2001     LBR  ﻿I am honoured to\\nparticipate in this histori...\n",
       "7504       56  2001     BDI  ﻿It\\nis for me a signal honour to take the flo...\n",
       "7505       56  2001     HUN  ﻿First, may I congratulate Mr. Han Seung-soo o...\n",
       "7506       56  2001     KWT  ﻿On behalf of the State of Kuwait, it\\ngives m...\n",
       "\n",
       "[7507 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### summarize texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import summarization transformer\n",
    "from transformers import pipeline\n",
    "summarization = pipeline(\"summarization\")\n",
    "\n",
    "# function to summarize text\n",
    "def summarize( input_text ):\n",
    "    try:\n",
    "        summary = summarization(input_text)[0]['summary_text']\n",
    " \n",
    "    # this except clause should be more specific, but will keep as is for now\n",
    "    except:\n",
    "        summary = ''\n",
    "        \n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 'summaries\\0.txt'\n",
      "processing 'summaries\\1.txt'\n",
      "processing 'summaries\\2.txt'\n",
      "processing 'summaries\\3.txt'\n",
      "processing 'summaries\\4.txt'\n",
      "processing 'summaries\\5.txt'\n",
      "processing 'summaries\\6.txt'\n",
      "processing 'summaries\\7.txt'\n",
      "processing 'summaries\\8.txt'\n",
      "processing 'summaries\\9.txt'\n",
      "processing 'summaries\\10.txt'\n",
      "processing 'summaries\\11.txt'\n",
      "processing 'summaries\\12.txt'\n",
      "processing 'summaries\\13.txt'\n",
      "processing 'summaries\\14.txt'\n",
      "processing 'summaries\\15.txt'\n",
      "processing 'summaries\\16.txt'\n",
      "processing 'summaries\\17.txt'\n",
      "processing 'summaries\\18.txt'\n",
      "processing 'summaries\\19.txt'\n",
      "processing 'summaries\\20.txt'\n",
      "processing 'summaries\\21.txt'\n",
      "processing 'summaries\\22.txt'\n",
      "processing 'summaries\\23.txt'\n",
      "processing 'summaries\\24.txt'\n",
      "processing 'summaries\\25.txt'\n",
      "processing 'summaries\\26.txt'\n",
      "processing 'summaries\\27.txt'\n",
      "processing 'summaries\\28.txt'\n",
      "processing 'summaries\\29.txt'\n",
      "processing 'summaries\\30.txt'\n",
      "processing 'summaries\\31.txt'\n",
      "processing 'summaries\\32.txt'\n",
      "processing 'summaries\\33.txt'\n",
      "processing 'summaries\\34.txt'\n",
      "processing 'summaries\\35.txt'\n",
      "processing 'summaries\\36.txt'\n",
      "processing 'summaries\\37.txt'\n",
      "processing 'summaries\\38.txt'\n",
      "processing 'summaries\\39.txt'\n",
      "processing 'summaries\\40.txt'\n",
      "processing 'summaries\\41.txt'\n",
      "processing 'summaries\\42.txt'\n",
      "processing 'summaries\\43.txt'\n",
      "processing 'summaries\\44.txt'\n",
      "processing 'summaries\\45.txt'\n",
      "processing 'summaries\\46.txt'\n",
      "processing 'summaries\\47.txt'\n",
      "processing 'summaries\\48.txt'\n",
      "processing 'summaries\\49.txt'\n",
      "processing 'summaries\\50.txt'\n",
      "processing 'summaries\\51.txt'\n",
      "processing 'summaries\\52.txt'\n",
      "processing 'summaries\\53.txt'\n",
      "processing 'summaries\\54.txt'\n",
      "processing 'summaries\\55.txt'\n",
      "processing 'summaries\\56.txt'\n",
      "processing 'summaries\\57.txt'\n",
      "processing 'summaries\\58.txt'\n",
      "processing 'summaries\\59.txt'\n",
      "processing 'summaries\\60.txt'\n",
      "processing 'summaries\\61.txt'\n",
      "processing 'summaries\\62.txt'\n",
      "processing 'summaries\\63.txt'\n",
      "processing 'summaries\\64.txt'\n",
      "processing 'summaries\\65.txt'\n",
      "processing 'summaries\\66.txt'\n",
      "processing 'summaries\\67.txt'\n",
      "processing 'summaries\\68.txt'\n",
      "processing 'summaries\\69.txt'\n",
      "processing 'summaries\\70.txt'\n",
      "processing 'summaries\\71.txt'\n",
      "processing 'summaries\\72.txt'\n",
      "processing 'summaries\\73.txt'\n",
      "processing 'summaries\\74.txt'\n",
      "processing 'summaries\\75.txt'\n",
      "processing 'summaries\\76.txt'\n",
      "processing 'summaries\\77.txt'\n",
      "processing 'summaries\\78.txt'\n",
      "processing 'summaries\\79.txt'\n",
      "processing 'summaries\\80.txt'\n",
      "processing 'summaries\\81.txt'\n",
      "processing 'summaries\\82.txt'\n",
      "processing 'summaries\\83.txt'\n",
      "processing 'summaries\\84.txt'\n",
      "processing 'summaries\\85.txt'\n",
      "processing 'summaries\\86.txt'\n",
      "processing 'summaries\\87.txt'\n",
      "processing 'summaries\\88.txt'\n",
      "processing 'summaries\\89.txt'\n",
      "processing 'summaries\\90.txt'\n",
      "processing 'summaries\\91.txt'\n",
      "processing 'summaries\\92.txt'\n",
      "processing 'summaries\\93.txt'\n",
      "processing 'summaries\\94.txt'\n",
      "processing 'summaries\\95.txt'\n",
      "processing 'summaries\\96.txt'\n",
      "processing 'summaries\\97.txt'\n",
      "processing 'summaries\\98.txt'\n",
      "processing 'summaries\\99.txt'\n",
      "processing 'summaries\\100.txt'\n",
      "processing 'summaries\\101.txt'\n",
      "processing 'summaries\\102.txt'\n",
      "processing 'summaries\\103.txt'\n",
      "processing 'summaries\\104.txt'\n",
      "processing 'summaries\\105.txt'\n",
      "processing 'summaries\\106.txt'\n",
      "processing 'summaries\\107.txt'\n",
      "processing 'summaries\\108.txt'\n",
      "processing 'summaries\\109.txt'\n",
      "processing 'summaries\\110.txt'\n",
      "processing 'summaries\\111.txt'\n",
      "processing 'summaries\\112.txt'\n",
      "processing 'summaries\\113.txt'\n",
      "processing 'summaries\\114.txt'\n",
      "processing 'summaries\\115.txt'\n",
      "processing 'summaries\\116.txt'\n",
      "processing 'summaries\\117.txt'\n",
      "processing 'summaries\\118.txt'\n",
      "processing 'summaries\\119.txt'\n",
      "processing 'summaries\\120.txt'\n",
      "processing 'summaries\\121.txt'\n",
      "processing 'summaries\\122.txt'\n",
      "processing 'summaries\\123.txt'\n",
      "processing 'summaries\\124.txt'\n",
      "processing 'summaries\\125.txt'\n",
      "processing 'summaries\\126.txt'\n",
      "processing 'summaries\\127.txt'\n",
      "processing 'summaries\\128.txt'\n",
      "processing 'summaries\\129.txt'\n",
      "processing 'summaries\\130.txt'\n",
      "processing 'summaries\\131.txt'\n",
      "processing 'summaries\\132.txt'\n",
      "processing 'summaries\\133.txt'\n",
      "processing 'summaries\\134.txt'\n",
      "processing 'summaries\\135.txt'\n",
      "processing 'summaries\\136.txt'\n",
      "processing 'summaries\\137.txt'\n",
      "processing 'summaries\\138.txt'\n",
      "processing 'summaries\\139.txt'\n",
      "processing 'summaries\\140.txt'\n",
      "processing 'summaries\\141.txt'\n",
      "processing 'summaries\\142.txt'\n",
      "processing 'summaries\\143.txt'\n",
      "processing 'summaries\\144.txt'\n",
      "processing 'summaries\\145.txt'\n",
      "processing 'summaries\\146.txt'\n",
      "processing 'summaries\\147.txt'\n",
      "processing 'summaries\\148.txt'\n",
      "processing 'summaries\\149.txt'\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# do subset of texts due to computation constraints (each summarization takes ~5 mins)\n",
    "num_texts = 150\n",
    "\n",
    "# summarizer can deal with 1024 words max, use 512 as stable limit\n",
    "word_threshold = 512\n",
    "\n",
    "# create save directory for individual files\n",
    "save_dir = Path('summaries')\n",
    "save_dir.mkdir(exist_ok = True)\n",
    "\n",
    "for i in range(num_texts):\n",
    "    # temporary file to save individual summary\n",
    "    summary_filename = Path(f'summaries/{i}.txt')\n",
    "    print(f'processing \\'{summary_filename}\\'')\n",
    "\n",
    "    # skip if already summarized\n",
    "    if summary_filename.exists():  continue\n",
    "    \n",
    "    # get text\n",
    "    original_text = Data.at[i, 'text']\n",
    "    # break into sentences\n",
    "    sentences = original_text.split('\\n')\n",
    "\n",
    "    # overall summary\n",
    "    total_summary = ''\n",
    "\n",
    "    # reset word count\n",
    "    word_count = 0\n",
    "    grouped_text = ''\n",
    "    \n",
    "    # reverse sentence order to facilitate pop\n",
    "    sentences.reverse()\n",
    "\n",
    "    # summarize each group of sentences\n",
    "    # note: in rare cases, the final group of sentences may be small\n",
    "    while sentences:\n",
    "        next_sentence = sentences.pop()\n",
    "        num_words = len(next_sentence.split(' '))\n",
    "\n",
    "        word_count += num_words\n",
    "        grouped_text += next_sentence\n",
    "        \n",
    "        if word_count >= word_threshold:\n",
    "            # summarize sentence and append to total summary\n",
    "            total_summary += summarize(grouped_text)\n",
    "\n",
    "            # reset word count and group_text\n",
    "            word_count = 0\n",
    "            grouped_text = ''\n",
    "\n",
    "    # finally, summarize group-wise summary\n",
    "    summary_text = summarize(total_summary)\n",
    "\n",
    "    # save summary\n",
    "    with open(summary_filename, 'w') as file:\n",
    "        file.write(summary_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of output file\n",
    "output_csv = 'summaries.csv'\n",
    "\n",
    "# copy dataframe for storing summaries; rename column from text to summary\n",
    "summaries_df = Data.copy()\n",
    "summaries_df.rename(columns = {'text': 'summary'}, inplace = True)\n",
    "\n",
    "summaries_df.at[:,'summary'] = 'Summary not available due to computational constraints.'\n",
    "\n",
    "for i in range(num_texts):\n",
    "    summary_filename = Path(f'summaries/{i}.txt')\n",
    "    \n",
    "    with open(summary_filename, 'r') as file:\n",
    "        summary_text = file.read()\n",
    "        summaries_df.at[i, 'summary'] = summary_text\n",
    "\n",
    "\n",
    "# write to csv\n",
    "summaries_df.to_csv(output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
